{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u /content/drive\n",
        "!rm -rf /content/drive"
      ],
      "metadata": {
        "id": "9c5Nze3DD7l5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db61752f-c5ae-4bf5-babe-82db234436c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusermount: failed to unmount /content/drive: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blocks Approach"
      ],
      "metadata": {
        "id": "s_qB3MmtereQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import math\n",
        "import os\n",
        "\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_PATH = \"/content/drive/My Drive/ASCP PW/2. BLOCKS\"\n",
        "except ImportError:\n",
        "    BASE_PATH = \"./\" # Adjust if your script is elsewhere relative to data/output\n",
        "\n",
        "INPUT_FOLDER = os.path.join(BASE_PATH, \"TRIPS_PER_DAY_CSV\") # Assuming CSVs are directly in BASE_PATH\n",
        "OUTPUT_FOLDER = os.path.join(BASE_PATH, \"Blocks Analysis\")\n",
        "\n",
        "ORDERS_FILE = os.path.join(INPUT_FOLDER, \"1603.csv\")\n",
        "DISTANCES_FILE = os.path.join(INPUT_FOLDER, \"Driving_Distances.csv\")\n",
        "\n",
        "\n",
        "BASE_LOCATION = 'BIA'\n",
        "\n",
        "# Average truck speeds (km/h)\n",
        "SPEED_UP_TO_25KM = 30\n",
        "SPEED_25_TO_50KM = 37.5  # Using average of 35-40 km/h\n",
        "SPEED_50_TO_100KM = 50\n",
        "SPEED_ABOVE_100KM = 60\n",
        "\n",
        "# Operations times (minutes)\n",
        "OPERATIONS_TIME_FV = 75\n",
        "OPERATIONS_TIME_LAS = 60\n",
        "OPERATIONS_TIME_DROGE = 45\n",
        "OPERATIONS_TIME_EXTRA = 30\n",
        "\n",
        "# Waiting time per point (minutes)\n",
        "WAITING_TIME_PER_POINT = 15\n",
        "\n",
        "# Special code time (minutes)\n",
        "SPECIAL_CODE_TIME_VALUE = 45\n",
        "SPECIAL_CODES_LIST = ['BV', 'RPV', 'V', 'VUOTI']\n",
        "\n",
        "# Start time flexibility (minutes)\n",
        "FLEXIBILITY_LAS = 0\n",
        "FLEXIBILITY_FV = 15\n",
        "FLEXIBILITY_DROGE = 15\n",
        "FLEXIBILITY_EXTRA = 30\n",
        "\n",
        "# Constraints (minutes)\n",
        "MAX_DAILY_DRIVING_STD = 9 * 60\n",
        "MAX_DAILY_DRIVING_EXT = 10 * 60\n",
        "MAX_CONTINUOUS_DRIVING = 4.5 * 60\n",
        "MAX_DAILY_WORKING_STD = 13 * 60\n",
        "MAX_DAILY_WORKING_EXT = 15 * 60\n",
        "MIN_DAILY_WORKING = 8 * 60\n",
        "\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_distance_lookup(distances_file_path):\n",
        "    \"\"\"Loads distances into a lookup dictionary.\"\"\"\n",
        "    try:\n",
        "        distances_df = pd.read_csv(distances_file_path)\n",
        "        lookup = {}\n",
        "        for _, row in distances_df.iterrows():\n",
        "            p1_clean = str(row['ORIGIN']).strip()\n",
        "            p2_clean = str(row['DESTINATION']).strip()\n",
        "            pair1 = tuple(sorted((p1_clean, p2_clean)))\n",
        "            lookup[pair1] = float(row['DISTANCE'])\n",
        "        return lookup\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Distances file not found at {distances_file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading distances: {e}\")\n",
        "        return None\n",
        "\n",
        "_distances_lookup = None # Global cache for distances\n",
        "\n",
        "def get_distance(p1, p2):\n",
        "    \"\"\"Gets distance between two points using the lookup.\"\"\"\n",
        "    global _distances_lookup\n",
        "    if _distances_lookup is None:\n",
        "        print(\"Error: Distances lookup not initialized.\")\n",
        "        return float('inf')\n",
        "\n",
        "    p1_clean = str(p1).strip()\n",
        "    p2_clean = str(p2).strip()\n",
        "\n",
        "    if p1_clean == p2_clean:\n",
        "        return 0.0\n",
        "\n",
        "    pair = tuple(sorted((p1_clean, p2_clean)))\n",
        "    return _distances_lookup.get(pair, float('inf'))\n",
        "\n",
        "def calculate_segment_driving_time(distance_km):\n",
        "    \"\"\"Calculates driving time in minutes for a segment based on distance.\"\"\"\n",
        "    if distance_km == 0:\n",
        "        return 0\n",
        "    if distance_km == float('inf'):\n",
        "        return float('inf')\n",
        "\n",
        "    speed_kmh = 0\n",
        "    if distance_km <= 25:\n",
        "        speed_kmh = SPEED_UP_TO_25KM\n",
        "    elif distance_km <= 50:\n",
        "        speed_kmh = SPEED_25_TO_50KM\n",
        "    elif distance_km <= 100:\n",
        "        speed_kmh = SPEED_50_TO_100KM\n",
        "    else:\n",
        "        speed_kmh = SPEED_ABOVE_100KM\n",
        "\n",
        "    if speed_kmh == 0: return float('inf')\n",
        "    return math.ceil((distance_km / speed_kmh) * 60)\n",
        "\n",
        "def get_order_operations_time_val(order_type, description):\n",
        "    \"\"\"Gets operations time for an order.\"\"\"\n",
        "    if order_type == 'Standard':\n",
        "        if description == 'FV': return OPERATIONS_TIME_FV\n",
        "        elif description == 'LAS': return OPERATIONS_TIME_LAS\n",
        "        elif description == 'DROGE': return OPERATIONS_TIME_DROGE\n",
        "    elif order_type == 'Extra':\n",
        "        return OPERATIONS_TIME_EXTRA\n",
        "    return 0\n",
        "\n",
        "def get_order_total_waiting_time_val(points_list):\n",
        "    \"\"\"Gets total waiting time for an order.\"\"\"\n",
        "    num_non_bia_points = 0\n",
        "    for point in points_list:\n",
        "        if point and str(point).strip() != BASE_LOCATION:\n",
        "            num_non_bia_points += 1\n",
        "    return num_non_bia_points * WAITING_TIME_PER_POINT\n",
        "\n",
        "def get_start_flexibility(order_type, description):\n",
        "    \"\"\"Gets start time flexibility in minutes.\"\"\"\n",
        "    if order_type == 'Standard':\n",
        "        if description == 'LAS': return FLEXIBILITY_LAS\n",
        "        if description == 'FV': return FLEXIBILITY_FV\n",
        "        if description == 'DROGE': return FLEXIBILITY_DROGE\n",
        "    elif order_type == 'Extra':\n",
        "        return FLEXIBILITY_EXTRA\n",
        "    return 0\n",
        "\n",
        "def parse_datetime(time_str):\n",
        "    \"\"\"Parses date string into datetime object.\"\"\"\n",
        "    try:\n",
        "        return datetime.strptime(str(time_str).strip(), '%d/%m/%Y %H:%M')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(str(time_str).strip(), '%d/%m/%Y')\n",
        "        except ValueError:\n",
        "            # print(f\"Warning: Could not parse datetime string: {time_str}\") # Reduced verbosity\n",
        "            return None\n",
        "\n",
        "\n",
        "# --- Main Algorithm ---\n",
        "def optimize_deliveries():\n",
        "    global _distances_lookup\n",
        "    _distances_lookup = get_distance_lookup(DISTANCES_FILE)\n",
        "    if _distances_lookup is None:\n",
        "        print(\"Exiting due to distance lookup initialization failure.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Attempt to read with a common encoding, and fall back if needed.\n",
        "        try:\n",
        "            orders_df_initial = pd.read_csv(ORDERS_FILE, encoding='utf-8')\n",
        "        except UnicodeDecodeError:\n",
        "            print(\"UTF-8 decoding failed, trying with 'latin1' encoding for orders file.\")\n",
        "            orders_df_initial = pd.read_csv(ORDERS_FILE, encoding='latin1')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Orders file not found at {ORDERS_FILE}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading orders CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    # Pre-process orders\n",
        "    processed_orders = []\n",
        "    skipped_orders_due_to_time_parse = 0\n",
        "    for idx, order_row in orders_df_initial.iterrows():\n",
        "        order = order_row.to_dict()\n",
        "        # Store the original DataFrame index, which might be more stable than 'id' if 'id' is not unique or missing\n",
        "        order['original_order_id'] = order.get('ID', idx) # Prefer 'ID' column if exists, else use df index\n",
        "        order['original_df_index'] = idx\n",
        "\n",
        "\n",
        "        order['TYPE'] = str(order.get('TYPE', '')).strip()\n",
        "        order['DESCRIPTION'] = str(order.get('DESCRIPTION', '')).strip()\n",
        "        order['NOTES'] = str(order.get('NOTES', '')).strip()\n",
        "        order['START_original_str'] = str(order.get('START', '')) # Keep original start string for unassigned\n",
        "\n",
        "        order['start_datetime_orig'] = parse_datetime(order.get('START'))\n",
        "        if order['start_datetime_orig'] is None:\n",
        "            # print(f\"Skipping order original_id={order['original_order_id']} due to invalid START time: {order.get('START')}\")\n",
        "            skipped_orders_due_to_time_parse +=1\n",
        "            continue\n",
        "\n",
        "        order['flexibility_minutes'] = get_start_flexibility(order['TYPE'], order['DESCRIPTION'])\n",
        "        order['earliest_start_dt'] = order['start_datetime_orig']\n",
        "        order['latest_start_dt'] = order['start_datetime_orig'] + timedelta(minutes=order['flexibility_minutes'])\n",
        "\n",
        "        points = []\n",
        "        for i in range(1, 7):\n",
        "            pt_val = str(order.get(f'POINT_{i}', '')).strip()\n",
        "            if pt_val and pd.notna(pt_val) and pt_val.lower() != 'nan' and pt_val.lower() != '':\n",
        "                points.append(pt_val)\n",
        "        order['points_list_orig'] = list(points)\n",
        "\n",
        "        order_special_code_time = 0\n",
        "        current_points_for_processing = list(points) # Work with a copy\n",
        "        if any(code in order['NOTES'] for code in SPECIAL_CODES_LIST):\n",
        "            order_special_code_time = SPECIAL_CODE_TIME_VALUE\n",
        "            if not current_points_for_processing or current_points_for_processing[-1] != BASE_LOCATION:\n",
        "                if len(current_points_for_processing) < 6:\n",
        "                    current_points_for_processing.append(BASE_LOCATION)\n",
        "                else:\n",
        "                    current_points_for_processing[-1] = BASE_LOCATION\n",
        "        order['points_list_final'] = list(current_points_for_processing) # Use the potentially modified list\n",
        "        order['inherent_special_code_time'] = order_special_code_time\n",
        "\n",
        "        order_trip_driving_time = 0\n",
        "        if not order['points_list_final']:\n",
        "             # print(f\"Warning: Order original_id={order['original_order_id']} has no points in points_list_final.\")\n",
        "             pass # Driving time remains 0\n",
        "        elif len(order['points_list_final']) >= 2:\n",
        "            for i in range(len(order['points_list_final']) - 1):\n",
        "                p1 = order['points_list_final'][i]\n",
        "                p2 = order['points_list_final'][i+1]\n",
        "                dist = get_distance(p1, p2)\n",
        "                if dist == float('inf'):\n",
        "                    # print(f\"Warning: Missing distance for order original_id={order['original_order_id']} between {p1} and {p2}.\")\n",
        "                    order_trip_driving_time = float('inf')\n",
        "                    break\n",
        "                order_trip_driving_time += calculate_segment_driving_time(dist)\n",
        "\n",
        "        if order_trip_driving_time == float('inf'):\n",
        "            # print(f\"Skipping order original_id={order['original_order_id']} due to missing distance in its path.\")\n",
        "            # This order will be considered unassigned later\n",
        "            order['reason_unassigned'] = \"Missing distance in its path\"\n",
        "            processed_orders.append(order) # Add to processed so it can be listed as unassigned\n",
        "            continue\n",
        "\n",
        "\n",
        "        order['inherent_trip_driving_time'] = order_trip_driving_time\n",
        "        order['inherent_operations_time'] = get_order_operations_time_val(order['TYPE'], order['DESCRIPTION'])\n",
        "        order['inherent_total_waiting_time'] = get_order_total_waiting_time_val(order['points_list_final'])\n",
        "\n",
        "        order['fixed_duration_components'] = (order['inherent_trip_driving_time'] +\n",
        "                                              order['inherent_operations_time'] +\n",
        "                                              order['inherent_total_waiting_time'] +\n",
        "                                              order['inherent_special_code_time'])\n",
        "        order['reason_unassigned'] = '' # Initialize, will be set if assignment fails\n",
        "        processed_orders.append(order)\n",
        "\n",
        "    if skipped_orders_due_to_time_parse > 0:\n",
        "        print(f\"Note: Skipped {skipped_orders_due_to_time_parse} orders during pre-processing due to invalid START times.\")\n",
        "\n",
        "    processed_orders.sort(key=lambda o: (o['earliest_start_dt'], o['original_order_id']))\n",
        "\n",
        "    drivers_plan = []\n",
        "    assigned_order_ids = set() # Store original_order_id\n",
        "    driver_id_counter = 0 # This will be used for Block ID\n",
        "\n",
        "    # Main Assignment Loop\n",
        "    while True:\n",
        "        made_assignment_in_iteration = False\n",
        "        best_assignment_for_existing_driver = None\n",
        "        best_assignment_score = float('inf')\n",
        "\n",
        "        eligible_orders_for_assignment = [o for o in processed_orders if o['original_order_id'] not in assigned_order_ids and o.get('inherent_trip_driving_time', 0) != float('inf')]\n",
        "\n",
        "\n",
        "        if not eligible_orders_for_assignment:\n",
        "            # print(\"No more eligible orders to assign.\")\n",
        "            break\n",
        "\n",
        "        # Try to assign to an existing driver\n",
        "        for driver_idx, driver_block in enumerate(drivers_plan):\n",
        "            if driver_block.get('finalized', False): continue\n",
        "\n",
        "            last_order_in_block = driver_block['orders'][-1]\n",
        "            prev_order_actual_end_time = last_order_in_block['actual_end_time']\n",
        "\n",
        "            if not last_order_in_block['points_list_final']:\n",
        "                continue\n",
        "            prev_order_last_point = last_order_in_block['points_list_final'][-1]\n",
        "\n",
        "            for order_to_assign in eligible_orders_for_assignment:\n",
        "                if not order_to_assign['points_list_final']:\n",
        "                    continue\n",
        "                next_order_first_point = order_to_assign['points_list_final'][0]\n",
        "\n",
        "                deadhead_dist = get_distance(prev_order_last_point, next_order_first_point)\n",
        "                if deadhead_dist == float('inf'):\n",
        "                    order_to_assign['reason_unassigned'] = f\"Missing deadhead from {prev_order_last_point} to {next_order_first_point}\"\n",
        "                    continue\n",
        "                deadhead_time_to_next = calculate_segment_driving_time(deadhead_dist)\n",
        "\n",
        "                earliest_arrival_at_next_p1 = prev_order_actual_end_time + timedelta(minutes=deadhead_time_to_next)\n",
        "                actual_start_for_next_order = max(earliest_arrival_at_next_p1, order_to_assign['earliest_start_dt'])\n",
        "\n",
        "                if actual_start_for_next_order > order_to_assign['latest_start_dt']:\n",
        "                    order_to_assign['reason_unassigned'] = f\"Cannot meet delivery window (latest: {order_to_assign['latest_start_dt']}, earliest possible: {actual_start_for_next_order})\"\n",
        "                    continue\n",
        "\n",
        "                idle_time_val = max(0, (actual_start_for_next_order - earliest_arrival_at_next_p1).total_seconds() / 60)\n",
        "\n",
        "                temp_return_to_bia_time = 0\n",
        "                if order_to_assign['points_list_final'][-1] != BASE_LOCATION:\n",
        "                    dist_to_bia = get_distance(order_to_assign['points_list_final'][-1], BASE_LOCATION)\n",
        "                    if dist_to_bia != float('inf'):\n",
        "                        temp_return_to_bia_time = calculate_segment_driving_time(dist_to_bia)\n",
        "                    else:\n",
        "                        temp_return_to_bia_time = float('inf') # Makes this assignment invalid for checks\n",
        "\n",
        "                proj_trip_driving = driver_block['sum_trip_driving_time'] + order_to_assign['inherent_trip_driving_time']\n",
        "                proj_deadhead_driving = driver_block['sum_deadhead_driving_time'] + deadhead_time_to_next\n",
        "                proj_total_driving = proj_trip_driving + proj_deadhead_driving + temp_return_to_bia_time\n",
        "\n",
        "                proj_ops = driver_block['sum_operations_time'] + order_to_assign['inherent_operations_time']\n",
        "                proj_wait = driver_block['sum_waiting_time'] + order_to_assign['inherent_total_waiting_time']\n",
        "                proj_special = driver_block['sum_special_code_time'] + order_to_assign['inherent_special_code_time']\n",
        "                proj_pure_idle = driver_block['sum_pure_idle_time'] + idle_time_val\n",
        "                proj_total_working = proj_total_driving + proj_ops + proj_wait + proj_special + proj_pure_idle\n",
        "\n",
        "                # Continuous Driving Check\n",
        "                current_order_inherent_driving = order_to_assign['inherent_trip_driving_time']\n",
        "                if idle_time_val > 0 or not driver_block['last_activity_was_driving']:\n",
        "                    accumulated_continuous_driving_for_order = deadhead_time_to_next + current_order_inherent_driving\n",
        "                else:\n",
        "                    accumulated_continuous_driving_for_order = driver_block['continuous_driving_accumulator'] + deadhead_time_to_next + current_order_inherent_driving\n",
        "\n",
        "                if accumulated_continuous_driving_for_order > MAX_CONTINUOUS_DRIVING:\n",
        "                    order_to_assign['reason_unassigned'] = f\"Exceeds max continuous driving ({accumulated_continuous_driving_for_order} > {MAX_CONTINUOUS_DRIVING})\"\n",
        "                    continue\n",
        "\n",
        "                fits_std = (proj_total_driving <= MAX_DAILY_DRIVING_STD and proj_total_working <= MAX_DAILY_WORKING_STD)\n",
        "                fits_ext = (proj_total_driving <= MAX_DAILY_DRIVING_EXT and proj_total_working <= MAX_DAILY_WORKING_EXT)\n",
        "\n",
        "                can_assign = False\n",
        "                used_extended = False\n",
        "                if fits_std: can_assign = True\n",
        "                elif fits_ext: can_assign = True; used_extended = True\n",
        "\n",
        "                if can_assign:\n",
        "                    score = idle_time_val + deadhead_time_to_next\n",
        "                    if used_extended: score += 1000\n",
        "\n",
        "                    if score < best_assignment_score:\n",
        "                        best_assignment_score = score\n",
        "                        best_assignment_for_existing_driver = {\n",
        "                            'order': order_to_assign, 'driver_idx': driver_idx, 'score': score,\n",
        "                            'actual_start': actual_start_for_next_order,\n",
        "                            'idle_time': idle_time_val, 'deadhead_time': deadhead_time_to_next,\n",
        "                            'continuous_driving_val_for_order': accumulated_continuous_driving_for_order,\n",
        "                            'used_extended': used_extended\n",
        "                        }\n",
        "\n",
        "        if best_assignment_for_existing_driver:\n",
        "            assign_details = best_assignment_for_existing_driver\n",
        "            order = assign_details['order']\n",
        "            driver_block = drivers_plan[assign_details['driver_idx']]\n",
        "\n",
        "            order['actual_start_time'] = assign_details['actual_start']\n",
        "            order['actual_end_time'] = order['actual_start_time'] + timedelta(minutes=order['fixed_duration_components'])\n",
        "\n",
        "            driver_block['orders'].append(order)\n",
        "            driver_block['sum_trip_driving_time'] += order['inherent_trip_driving_time']\n",
        "            driver_block['sum_deadhead_driving_time'] += assign_details['deadhead_time']\n",
        "            driver_block['sum_operations_time'] += order['inherent_operations_time']\n",
        "            driver_block['sum_waiting_time'] += order['inherent_total_waiting_time']\n",
        "            driver_block['sum_special_code_time'] += order['inherent_special_code_time']\n",
        "            driver_block['sum_pure_idle_time'] += assign_details['idle_time']\n",
        "\n",
        "            driver_block['continuous_driving_accumulator'] = assign_details['continuous_driving_val_for_order']\n",
        "            driver_block['last_activity_was_driving'] = not (order['inherent_operations_time'] > 0 or order['inherent_total_waiting_time'] > 0 or order['inherent_special_code_time'] > 0)\n",
        "            if not driver_block['last_activity_was_driving']:\n",
        "                driver_block['continuous_driving_accumulator'] = 0\n",
        "\n",
        "            if assign_details['used_extended']:\n",
        "                driver_block['used_extended_hours'] = True\n",
        "\n",
        "            assigned_order_ids.add(order['original_order_id'])\n",
        "            made_assignment_in_iteration = True\n",
        "\n",
        "        else: # No existing driver could take any of the remaining orders, try to start a new one\n",
        "            order_for_new_driver = None\n",
        "            best_new_driver_order_start_time = datetime.max\n",
        "            temp_new_driver_assignment_details = {}\n",
        "\n",
        "            for order_to_assign in eligible_orders_for_assignment: # Already filtered for not assigned and valid path\n",
        "                if not order_to_assign['points_list_final']:\n",
        "                    continue\n",
        "\n",
        "                initial_deadhead_time = 0\n",
        "                if order_to_assign['points_list_final'][0] != BASE_LOCATION:\n",
        "                    initial_deadhead_dist = get_distance(BASE_LOCATION, order_to_assign['points_list_final'][0])\n",
        "                    if initial_deadhead_dist == float('inf'):\n",
        "                        order_to_assign['reason_unassigned'] = f\"Missing initial deadhead from BIA to {order_to_assign['points_list_final'][0]}\"\n",
        "                        continue\n",
        "                    initial_deadhead_time = calculate_segment_driving_time(initial_deadhead_dist)\n",
        "\n",
        "                actual_start_for_order = order_to_assign['earliest_start_dt']\n",
        "                # No check against latest_start_dt here as it's the first order, assumed to be met.\n",
        "\n",
        "                temp_return_to_bia_time = 0\n",
        "                if order_to_assign['points_list_final'][-1] != BASE_LOCATION:\n",
        "                    dist_to_bia = get_distance(order_to_assign['points_list_final'][-1], BASE_LOCATION)\n",
        "                    if dist_to_bia != float('inf'):\n",
        "                        temp_return_to_bia_time = calculate_segment_driving_time(dist_to_bia)\n",
        "                    else: temp_return_to_bia_time = float('inf')\n",
        "\n",
        "                proj_trip_driving = order_to_assign['inherent_trip_driving_time']\n",
        "                proj_deadhead_driving = initial_deadhead_time\n",
        "                proj_total_driving = proj_trip_driving + proj_deadhead_driving + temp_return_to_bia_time\n",
        "\n",
        "                proj_ops = order_to_assign['inherent_operations_time']\n",
        "                proj_wait = order_to_assign['inherent_total_waiting_time']\n",
        "                proj_special = order_to_assign['inherent_special_code_time']\n",
        "                proj_pure_idle = 0\n",
        "                proj_total_working = proj_total_driving + proj_ops + proj_wait + proj_special + proj_pure_idle\n",
        "\n",
        "                continuous_driving_segment = initial_deadhead_time + order_to_assign['inherent_trip_driving_time']\n",
        "                if continuous_driving_segment > MAX_CONTINUOUS_DRIVING:\n",
        "                    order_to_assign['reason_unassigned'] = f\"Exceeds max continuous driving for new driver ({continuous_driving_segment})\"\n",
        "                    continue\n",
        "\n",
        "                fits_std = (proj_total_driving <= MAX_DAILY_DRIVING_STD and proj_total_working <= MAX_DAILY_WORKING_STD)\n",
        "                fits_ext = (proj_total_driving <= MAX_DAILY_DRIVING_EXT and proj_total_working <= MAX_DAILY_WORKING_EXT)\n",
        "\n",
        "                can_assign_new = False\n",
        "                used_extended_new = False\n",
        "                if fits_std: can_assign_new = True\n",
        "                elif fits_ext: can_assign_new = True; used_extended_new = True\n",
        "\n",
        "                if can_assign_new:\n",
        "                    if order_to_assign['earliest_start_dt'] < best_new_driver_order_start_time:\n",
        "                        best_new_driver_order_start_time = order_to_assign['earliest_start_dt']\n",
        "                        order_for_new_driver = order_to_assign\n",
        "                        temp_new_driver_assignment_details = {\n",
        "                            'order': order_to_assign, 'actual_start': actual_start_for_order,\n",
        "                            'initial_deadhead': initial_deadhead_time,\n",
        "                            'continuous_driving_val': continuous_driving_segment,\n",
        "                            'used_extended': used_extended_new\n",
        "                        }\n",
        "\n",
        "            if order_for_new_driver:\n",
        "                assign_details = temp_new_driver_assignment_details\n",
        "                order = assign_details['order']\n",
        "                driver_id_counter += 1 # This is now the Block ID\n",
        "\n",
        "                order['actual_start_time'] = assign_details['actual_start']\n",
        "                order['actual_end_time'] = order['actual_start_time'] + timedelta(minutes=order['fixed_duration_components'])\n",
        "\n",
        "                new_block = {\n",
        "                    'block_id': driver_id_counter,\n",
        "                    'orders': [order],\n",
        "                    'sum_trip_driving_time': order['inherent_trip_driving_time'],\n",
        "                    'sum_deadhead_driving_time': assign_details['initial_deadhead'],\n",
        "                    'sum_operations_time': order['inherent_operations_time'],\n",
        "                    'sum_waiting_time': order['inherent_total_waiting_time'],\n",
        "                    'sum_special_code_time': order['inherent_special_code_time'],\n",
        "                    'sum_pure_idle_time': 0,\n",
        "                    'return_trip_driving_time': 0,\n",
        "                    'continuous_driving_accumulator': assign_details['continuous_driving_val'],\n",
        "                    'last_activity_was_driving': not (order['inherent_operations_time'] > 0 or order['inherent_total_waiting_time'] > 0 or order['inherent_special_code_time'] > 0),\n",
        "                    'used_extended_hours': assign_details['used_extended']\n",
        "                }\n",
        "                if not new_block['last_activity_was_driving']: new_block['continuous_driving_accumulator'] = 0\n",
        "\n",
        "                drivers_plan.append(new_block)\n",
        "                assigned_order_ids.add(order['original_order_id'])\n",
        "                made_assignment_in_iteration = True\n",
        "\n",
        "        if not made_assignment_in_iteration:\n",
        "            # print(\"No assignment could be made in this iteration for any remaining orders.\")\n",
        "            break # Exit while loop if no progress\n",
        "\n",
        "    # --- Prepare Output Data ---\n",
        "    optimized_plan_rows = []\n",
        "    for driver_block in drivers_plan: # driver_block is actually just 'block' now\n",
        "        if not driver_block['orders']: continue\n",
        "\n",
        "        last_order_of_block = driver_block['orders'][-1]\n",
        "        final_location = BASE_LOCATION\n",
        "        if last_order_of_block['points_list_final']:\n",
        "            final_location = last_order_of_block['points_list_final'][-1]\n",
        "\n",
        "        driver_return_trip_time = 0\n",
        "        if final_location != BASE_LOCATION:\n",
        "            dist = get_distance(final_location, BASE_LOCATION)\n",
        "            if dist != float('inf'):\n",
        "                driver_return_trip_time = calculate_segment_driving_time(dist)\n",
        "                driver_block['return_trip_driving_time'] = driver_return_trip_time\n",
        "            else:\n",
        "                driver_block['return_trip_driving_time'] = 0\n",
        "                # print(f\"Warning: Could not calculate return to BIA for block {driver_block['block_id']} from {final_location}\")\n",
        "\n",
        "        driver_block['total_driving_time_final'] = (driver_block['sum_trip_driving_time'] +\n",
        "                                                    driver_block['sum_deadhead_driving_time'] +\n",
        "                                                    driver_block['return_trip_driving_time'])\n",
        "\n",
        "        driver_block['total_working_time_final'] = (driver_block['total_driving_time_final'] +\n",
        "                                                    driver_block['sum_operations_time'] +\n",
        "                                                    driver_block['sum_waiting_time'] +\n",
        "                                                    driver_block['sum_special_code_time'] +\n",
        "                                                    driver_block['sum_pure_idle_time'])\n",
        "\n",
        "        for trip_idx, trip_order in enumerate(driver_block['orders']):\n",
        "            prev_loc_for_deadhead = BASE_LOCATION\n",
        "            if trip_idx > 0:\n",
        "                prev_trip_in_block = driver_block['orders'][trip_idx-1]\n",
        "                if prev_trip_in_block['points_list_final']:\n",
        "                     prev_loc_for_deadhead = prev_trip_in_block['points_list_final'][-1]\n",
        "\n",
        "            current_trip_first_point = trip_order['points_list_final'][0] if trip_order['points_list_final'] else \"\"\n",
        "            deadhead_to_this_trip = 0\n",
        "            if current_trip_first_point and current_trip_first_point != prev_loc_for_deadhead :\n",
        "                 dist_deadhead = get_distance(prev_loc_for_deadhead, current_trip_first_point)\n",
        "                 if dist_deadhead != float('inf'):\n",
        "                     deadhead_to_this_trip = calculate_segment_driving_time(dist_deadhead)\n",
        "\n",
        "            row = {\n",
        "                # 'Driver ID': driver_block['driver_id'], # Removed as per request\n",
        "                'Block ID': driver_block['block_id'],\n",
        "                'Trip Order in Block': trip_idx + 1,\n",
        "                'Trip ID (Order ID)': trip_order['original_order_id'],\n",
        "                'Type': trip_order['TYPE'],\n",
        "                'Description': trip_order['DESCRIPTION'],\n",
        "                'Truck Type': trip_order.get('TRUCK_TYPE', 'TR'),\n",
        "                'Point 1': trip_order['points_list_final'][0] if len(trip_order['points_list_final']) > 0 else '',\n",
        "                'Point 2': trip_order['points_list_final'][1] if len(trip_order['points_list_final']) > 1 else '',\n",
        "                'Point 3': trip_order['points_list_final'][2] if len(trip_order['points_list_final']) > 2 else '',\n",
        "                'Point 4': trip_order['points_list_final'][3] if len(trip_order['points_list_final']) > 3 else '',\n",
        "                'Point 5': trip_order['points_list_final'][4] if len(trip_order['points_list_final']) > 4 else '',\n",
        "                'Point 6': trip_order['points_list_final'][5] if len(trip_order['points_list_final']) > 5 else '',\n",
        "                'Scheduled Start (Order)': trip_order['start_datetime_orig'].strftime('%d/%m/%Y %H:%M'),\n",
        "                'Actual Start Time (Trip)': trip_order['actual_start_time'].strftime('%d/%m/%Y %H:%M') if 'actual_start_time' in trip_order else '',\n",
        "                'Actual End Time (Trip)': trip_order['actual_end_time'].strftime('%d/%m/%Y %H:%M') if 'actual_end_time' in trip_order else '',\n",
        "                'NOTES': trip_order['NOTES'],\n",
        "                'SR': trip_order.get('SR', ''),\n",
        "                'Inherited Trip Driving (min)': trip_order['inherent_trip_driving_time'],\n",
        "                'Inherited Ops (min)': trip_order['inherent_operations_time'],\n",
        "                'Inherited Wait (min)': trip_order['inherent_total_waiting_time'],\n",
        "                'Inherited Special (min)': trip_order['inherent_special_code_time'],\n",
        "                'Deadhead To This Trip (min)': deadhead_to_this_trip\n",
        "            }\n",
        "            optimized_plan_rows.append(row)\n",
        "\n",
        "        if driver_block['return_trip_driving_time'] > 0:\n",
        "            return_start_time = last_order_of_block['actual_end_time']\n",
        "            return_end_time = return_start_time + timedelta(minutes=driver_block['return_trip_driving_time'])\n",
        "            row = {\n",
        "                # 'Driver ID': driver_block['driver_id'], # Removed\n",
        "                'Block ID': driver_block['block_id'],\n",
        "                'Trip Order in Block': len(driver_block['orders']) + 1,\n",
        "                'Trip ID (Order ID)': -1,\n",
        "                'Type': 'Return to Base',\n",
        "                'Description': f'Return from {final_location} to {BASE_LOCATION}',\n",
        "                'Truck Type': 'TR',\n",
        "                'Point 1': final_location, 'Point 2': BASE_LOCATION,\n",
        "                'Point 3': '', 'Point 4': '', 'Point 5': '', 'Point 6': '',\n",
        "                'Scheduled Start (Order)': '',\n",
        "                'Actual Start Time (Trip)': return_start_time.strftime('%d/%m/%Y %H:%M'),\n",
        "                'Actual End Time (Trip)': return_end_time.strftime('%d/%m/%Y %H:%M'),\n",
        "                'NOTES': 'AUTO_GENERATED_RETURN_TRIP', 'SR': '',\n",
        "                'Inherited Trip Driving (min)': driver_block['return_trip_driving_time'],\n",
        "                'Inherited Ops (min)': 0, 'Inherited Wait (min)': 0, 'Inherited Special (min)': 0,\n",
        "                'Deadhead To This Trip (min)': 0\n",
        "            }\n",
        "            optimized_plan_rows.append(row)\n",
        "\n",
        "    optimized_plan_df = pd.DataFrame(optimized_plan_rows)\n",
        "\n",
        "    # --- Prepare Unassigned Trips Data ---\n",
        "    unassigned_trips_rows = []\n",
        "    for order in processed_orders:\n",
        "        if order['original_order_id'] not in assigned_order_ids:\n",
        "            unassigned_row = {\n",
        "                'Order ID': order['original_order_id'],\n",
        "                'Original DF Index': order['original_df_index'],\n",
        "                'Type': order['TYPE'],\n",
        "                'Description': order['DESCRIPTION'],\n",
        "                'Scheduled Start': order['START_original_str'], # Original string value\n",
        "                'Earliest Parsed Start': order['earliest_start_dt'].strftime('%d/%m/%Y %H:%M') if pd.notnull(order['earliest_start_dt']) else '',\n",
        "                'Latest Parsed Start': order['latest_start_dt'].strftime('%d/%m/%Y %H:%M') if pd.notnull(order['latest_start_dt']) else '',\n",
        "                'Point 1': order['points_list_orig'][0] if len(order['points_list_orig']) > 0 else '',\n",
        "                'Point 2': order['points_list_orig'][1] if len(order['points_list_orig']) > 1 else '',\n",
        "                'Point 3': order['points_list_orig'][2] if len(order['points_list_orig']) > 2 else '',\n",
        "                'Point 4': order['points_list_orig'][3] if len(order['points_list_orig']) > 3 else '',\n",
        "                'Point 5': order['points_list_orig'][4] if len(order['points_list_orig']) > 4 else '',\n",
        "                'Point 6': order['points_list_orig'][5] if len(order['points_list_orig']) > 5 else '',\n",
        "                'NOTES': order['NOTES'],\n",
        "                'SR': order.get('SR', ''),\n",
        "                'Reason Unassigned': order.get('reason_unassigned', 'Not processed or no specific reason logged during assignment attempt')\n",
        "            }\n",
        "            unassigned_trips_rows.append(unassigned_row)\n",
        "    unassigned_trips_df = pd.DataFrame(unassigned_trips_rows)\n",
        "\n",
        "    # --- Prepare Summary Report Data ---\n",
        "    num_blocks_created = len(drivers_plan) # Each item in drivers_plan is a block\n",
        "    num_unassigned_trips = len(unassigned_trips_df)\n",
        "\n",
        "    total_block_duration_minutes = 0\n",
        "    if num_blocks_created > 0:\n",
        "        for block in drivers_plan:\n",
        "            total_block_duration_minutes += block.get('total_working_time_final', 0)\n",
        "        average_block_duration_minutes = total_block_duration_minutes / num_blocks_created\n",
        "    else:\n",
        "        average_block_duration_minutes = 0\n",
        "\n",
        "    summary_data = {\n",
        "        'Metric': ['Number of Blocks Created', 'Number of Unassigned Trips', 'Average Block Duration (minutes)'],\n",
        "        'Value': [num_blocks_created, num_unassigned_trips, f\"{average_block_duration_minutes:.2f}\"]\n",
        "    }\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "    # --- Write to Excel ---\n",
        "    if not os.path.exists(OUTPUT_FOLDER):\n",
        "        try:\n",
        "            os.makedirs(OUTPUT_FOLDER)\n",
        "            print(f\"Created output folder: {OUTPUT_FOLDER}\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error creating output folder {OUTPUT_FOLDER}: {e}\")\n",
        "            # Fallback to current directory if creation fails\n",
        "            print(\"Attempting to save output to current directory.\")\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_file_name = f'delivery_plan_optimized_{timestamp}.xlsx' # Save to script's dir\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_file_name = os.path.join(OUTPUT_FOLDER, f'delivery_plan_optimized_{timestamp}.xlsx')\n",
        "\n",
        "    try:\n",
        "        with pd.ExcelWriter(output_file_name, engine='openpyxl') as writer: # openpyxl is common in Colab\n",
        "            optimized_plan_df.to_excel(writer, sheet_name='Optimized Plan', index=False)\n",
        "            if not unassigned_trips_df.empty:\n",
        "                unassigned_trips_df.to_excel(writer, sheet_name='Unassigned Trips', index=False)\n",
        "            else:\n",
        "                # Create an empty sheet or a sheet with a message if no unassigned trips\n",
        "                pd.DataFrame([{'Status': 'No unassigned trips'}]).to_excel(writer, sheet_name='Unassigned Trips', index=False)\n",
        "            summary_df.to_excel(writer, sheet_name='Summary Report', index=False)\n",
        "        print(f\"Successfully generated multi-sheet delivery plan: {output_file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving Excel file: {e}\")\n",
        "        print(\"Make sure you have 'openpyxl' installed (pip install openpyxl).\")\n",
        "\n",
        "\n",
        "    # --- Console Evaluation ---\n",
        "    print(f\"\\n--- Evaluation ---\")\n",
        "    print(f\"Total orders in input file: {len(orders_df_initial)}\")\n",
        "    print(f\"Total orders pre-processed (valid for assignment attempt): {len(processed_orders) - skipped_orders_due_to_time_parse}\")\n",
        "    print(f\"Total orders assigned to blocks: {len(assigned_order_ids)}\")\n",
        "    print(f\"Total orders unassigned: {num_unassigned_trips}\")\n",
        "\n",
        "    if num_unassigned_trips > 0:\n",
        "        print(\"First 5 Unassigned order IDs and reasons (if available):\")\n",
        "        for i, row in unassigned_trips_df.head().iterrows():\n",
        "            print(f\"  Order ID: {row['Order ID']}, Reason: {row.get('Reason Unassigned', 'N/A')}\")\n",
        "\n",
        "\n",
        "    print(f\"Number of blocks created: {num_blocks_created}\")\n",
        "    print(f\"Average block duration: {average_block_duration_minutes:.2f} minutes\")\n",
        "\n",
        "    for i, driver_block in enumerate(drivers_plan): # driver_block is block\n",
        "        block_start_time_str = \"\"\n",
        "        block_end_time_str = \"\"\n",
        "        if driver_block['orders']:\n",
        "            first_order_actual_start = driver_block['orders'][0]['actual_start_time']\n",
        "\n",
        "            # Calculate initial deadhead for this specific block to find effective start\n",
        "            initial_deadhead_for_block = 0\n",
        "            first_order_first_point = driver_block['orders'][0]['points_list_final'][0] if driver_block['orders'][0]['points_list_final'] else None\n",
        "            if first_order_first_point and first_order_first_point != BASE_LOCATION:\n",
        "                dist = get_distance(BASE_LOCATION, first_order_first_point)\n",
        "                if dist != float('inf'):\n",
        "                    initial_deadhead_for_block = calculate_segment_driving_time(dist)\n",
        "\n",
        "            effective_block_start = first_order_actual_start - timedelta(minutes=initial_deadhead_for_block)\n",
        "            block_start_time_str = effective_block_start.strftime('%d/%m/%Y %H:%M')\n",
        "\n",
        "            last_order_actual_end = driver_block['orders'][-1]['actual_end_time']\n",
        "            effective_block_end = last_order_actual_end + timedelta(minutes=driver_block.get('return_trip_driving_time',0))\n",
        "            block_end_time_str = effective_block_end.strftime('%d/%m/%Y %H:%M')\n",
        "\n",
        "\n",
        "        print(f\"  Block ID {driver_block['block_id']}: {len(driver_block['orders'])} trips assigned.\")\n",
        "        if block_start_time_str and block_end_time_str:\n",
        "             print(f\"    Effective Block Time (incl. initial deadhead & final return): {block_start_time_str} to {block_end_time_str}\")\n",
        "        print(f\"    Total Driving Time (incl. deadhead & return): {driver_block['total_driving_time_final'] / 60:.2f} hrs\")\n",
        "        print(f\"    Total Working Time (calculated for block): {driver_block['total_working_time_final'] / 60:.2f} hrs (Min 8hr target: {driver_block['total_working_time_final'] >= MIN_DAILY_WORKING})\")\n",
        "\n",
        "        used_extended_flag = driver_block.get('used_extended_hours', False) or \\\n",
        "                             driver_block['total_driving_time_final'] > MAX_DAILY_DRIVING_STD or \\\n",
        "                             driver_block['total_working_time_final'] > MAX_DAILY_WORKING_STD\n",
        "\n",
        "        if driver_block['total_driving_time_final'] > MAX_DAILY_DRIVING_EXT or \\\n",
        "           driver_block['total_working_time_final'] > MAX_DAILY_WORKING_EXT:\n",
        "            print(f\"    WARNING: Block {driver_block['block_id']} EXCEEDED EXTENDED LIMITS! Driving: {driver_block['total_driving_time_final']/60:.2f}h, Working: {driver_block['total_working_time_final']/60:.2f}h\")\n",
        "        elif used_extended_flag:\n",
        "            print(\"    Used Extended Hours for this block.\")\n",
        "\n",
        "# This is the crucial part: calling the function to start the process.\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting delivery optimization process...\")\n",
        "    optimize_deliveries()\n",
        "    print(\"Delivery optimization process finished.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95x9-uRReuyg",
        "outputId": "2b32cd0d-9eb9-41e9-f230-16a5710cb3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Starting delivery optimization process...\n",
            "Successfully generated multi-sheet delivery plan: /content/drive/My Drive/ASCP PW/2. BLOCKS/Blocks Analysis/delivery_plan_optimized_20250527_082446.xlsx\n",
            "\n",
            "--- Evaluation ---\n",
            "Total orders in input file: 48\n",
            "Total orders pre-processed (valid for assignment attempt): 48\n",
            "Total orders assigned to blocks: 43\n",
            "Total orders unassigned: 5\n",
            "First 5 Unassigned order IDs and reasons (if available):\n",
            "  Order ID: 24, Reason: Exceeds max continuous driving for new driver (274)\n",
            "  Order ID: 42, Reason: Exceeds max continuous driving for new driver (274)\n",
            "  Order ID: 26, Reason: Exceeds max continuous driving for new driver (461)\n",
            "  Order ID: 43, Reason: Exceeds max continuous driving for new driver (274)\n",
            "  Order ID: 44, Reason: Exceeds max continuous driving for new driver (461)\n",
            "Number of blocks created: 28\n",
            "Average block duration: 505.25 minutes\n",
            "  Block ID 1: 3 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 03:30 to 16/03/2025 16:59\n",
            "    Total Driving Time (incl. deadhead & return): 8.47 hrs\n",
            "    Total Working Time (calculated for block): 13.48 hrs (Min 8hr target: True)\n",
            "    Used Extended Hours for this block.\n",
            "  Block ID 2: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 03:45 to 16/03/2025 15:08\n",
            "    Total Driving Time (incl. deadhead & return): 7.90 hrs\n",
            "    Total Working Time (calculated for block): 11.38 hrs (Min 8hr target: True)\n",
            "  Block ID 3: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 03:45 to 16/03/2025 16:11\n",
            "    Total Driving Time (incl. deadhead & return): 6.28 hrs\n",
            "    Total Working Time (calculated for block): 12.43 hrs (Min 8hr target: True)\n",
            "  Block ID 4: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:00 to 16/03/2025 16:58\n",
            "    Total Driving Time (incl. deadhead & return): 7.62 hrs\n",
            "    Total Working Time (calculated for block): 12.97 hrs (Min 8hr target: True)\n",
            "  Block ID 5: 3 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:00 to 16/03/2025 16:55\n",
            "    Total Driving Time (incl. deadhead & return): 7.07 hrs\n",
            "    Total Working Time (calculated for block): 12.92 hrs (Min 8hr target: True)\n",
            "  Block ID 6: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:00 to 16/03/2025 15:39\n",
            "    Total Driving Time (incl. deadhead & return): 6.70 hrs\n",
            "    Total Working Time (calculated for block): 11.65 hrs (Min 8hr target: True)\n",
            "  Block ID 7: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:00 to 16/03/2025 15:55\n",
            "    Total Driving Time (incl. deadhead & return): 6.97 hrs\n",
            "    Total Working Time (calculated for block): 11.92 hrs (Min 8hr target: True)\n",
            "  Block ID 8: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 02:22 to 16/03/2025 12:21\n",
            "    Total Driving Time (incl. deadhead & return): 6.87 hrs\n",
            "    Total Working Time (calculated for block): 9.98 hrs (Min 8hr target: True)\n",
            "  Block ID 9: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:15 to 16/03/2025 19:13\n",
            "    Total Driving Time (incl. deadhead & return): 7.22 hrs\n",
            "    Total Working Time (calculated for block): 14.97 hrs (Min 8hr target: True)\n",
            "    Used Extended Hours for this block.\n",
            "  Block ID 10: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:30 to 16/03/2025 14:49\n",
            "    Total Driving Time (incl. deadhead & return): 6.75 hrs\n",
            "    Total Working Time (calculated for block): 10.32 hrs (Min 8hr target: True)\n",
            "  Block ID 11: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:30 to 16/03/2025 18:36\n",
            "    Total Driving Time (incl. deadhead & return): 4.72 hrs\n",
            "    Total Working Time (calculated for block): 14.10 hrs (Min 8hr target: True)\n",
            "    Used Extended Hours for this block.\n",
            "  Block ID 12: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:30 to 16/03/2025 08:52\n",
            "    Total Driving Time (incl. deadhead & return): 2.87 hrs\n",
            "    Total Working Time (calculated for block): 4.37 hrs (Min 8hr target: False)\n",
            "  Block ID 13: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:30 to 16/03/2025 09:17\n",
            "    Total Driving Time (incl. deadhead & return): 3.28 hrs\n",
            "    Total Working Time (calculated for block): 4.78 hrs (Min 8hr target: False)\n",
            "  Block ID 14: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 04:30 to 16/03/2025 09:03\n",
            "    Total Driving Time (incl. deadhead & return): 3.30 hrs\n",
            "    Total Working Time (calculated for block): 4.55 hrs (Min 8hr target: False)\n",
            "  Block ID 15: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 05:00 to 16/03/2025 09:43\n",
            "    Total Driving Time (incl. deadhead & return): 3.22 hrs\n",
            "    Total Working Time (calculated for block): 4.72 hrs (Min 8hr target: False)\n",
            "  Block ID 16: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 13:09\n",
            "    Total Driving Time (incl. deadhead & return): 4.40 hrs\n",
            "    Total Working Time (calculated for block): 5.90 hrs (Min 8hr target: False)\n",
            "  Block ID 17: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 12:41\n",
            "    Total Driving Time (incl. deadhead & return): 3.68 hrs\n",
            "    Total Working Time (calculated for block): 5.43 hrs (Min 8hr target: False)\n",
            "  Block ID 18: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 15:31\n",
            "    Total Driving Time (incl. deadhead & return): 6.77 hrs\n",
            "    Total Working Time (calculated for block): 8.27 hrs (Min 8hr target: True)\n",
            "  Block ID 19: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 11:43\n",
            "    Total Driving Time (incl. deadhead & return): 2.97 hrs\n",
            "    Total Working Time (calculated for block): 4.47 hrs (Min 8hr target: False)\n",
            "  Block ID 20: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 12:03\n",
            "    Total Driving Time (incl. deadhead & return): 3.30 hrs\n",
            "    Total Working Time (calculated for block): 4.80 hrs (Min 8hr target: False)\n",
            "  Block ID 21: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 17:41\n",
            "    Total Driving Time (incl. deadhead & return): 6.25 hrs\n",
            "    Total Working Time (calculated for block): 10.43 hrs (Min 8hr target: True)\n",
            "  Block ID 22: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 12:39\n",
            "    Total Driving Time (incl. deadhead & return): 3.90 hrs\n",
            "    Total Working Time (calculated for block): 5.40 hrs (Min 8hr target: False)\n",
            "  Block ID 23: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 12:11\n",
            "    Total Driving Time (incl. deadhead & return): 3.18 hrs\n",
            "    Total Working Time (calculated for block): 4.93 hrs (Min 8hr target: False)\n",
            "  Block ID 24: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 12:28\n",
            "    Total Driving Time (incl. deadhead & return): 3.47 hrs\n",
            "    Total Working Time (calculated for block): 5.22 hrs (Min 8hr target: False)\n",
            "  Block ID 25: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 07:15 to 16/03/2025 11:33\n",
            "    Total Driving Time (incl. deadhead & return): 2.80 hrs\n",
            "    Total Working Time (calculated for block): 4.30 hrs (Min 8hr target: False)\n",
            "  Block ID 26: 2 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 12:00 to 17/03/2025 01:10\n",
            "    Total Driving Time (incl. deadhead & return): 9.30 hrs\n",
            "    Total Working Time (calculated for block): 13.17 hrs (Min 8hr target: True)\n",
            "    Used Extended Hours for this block.\n",
            "  Block ID 27: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 21:20 to 17/03/2025 01:25\n",
            "    Total Driving Time (incl. deadhead & return): 3.33 hrs\n",
            "    Total Working Time (calculated for block): 4.08 hrs (Min 8hr target: False)\n",
            "  Block ID 28: 1 trips assigned.\n",
            "    Effective Block Time (incl. initial deadhead & final return): 16/03/2025 23:00 to 17/03/2025 03:51\n",
            "    Total Driving Time (incl. deadhead & return): 3.60 hrs\n",
            "    Total Working Time (calculated for block): 4.85 hrs (Min 8hr target: False)\n",
            "Delivery optimization process finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "s_qB3MmtereQ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}